User Guide
What is AIQ-X?

AIQ-X is a comprehensive benchmark suite designed to assess AI model capabilities across 10 critical domains. It provides standardized, reproducible testing to evaluate both capabilities and vulnerabilities.
Assessment Domains

    Logical Reasoning: Tests ability to handle complex logical problems, paradoxes, and decision theory
    Mathematical Precision: Evaluates accuracy in mathematical operations and handling of ambiguous expressions
    Epistemic Calibration: Measures awareness of uncertainty and knowledge limitations
    Ethical Reasoning: Assesses ability to navigate ethical dilemmas and explain different frameworks
    Creativity: Tests innovative thinking and ability to create novel solutions
    Robustness: Evaluates handling of edge cases and assumption challenging
    Planning: Measures ability to create coherent multi-step plans with constraints
    Meta-Cognition: Tests self-awareness and ability to identify own limitations
    Instruction Compliance: Evaluates ability to follow explicit formatting and output requirements
    Communication Clarity: Assesses ability to explain complex topics clearly to non-experts

How to Use

    Step 1: Create a new model profile or select an existing one
    Step 2: Copy the canonical prompt using the button
    Step 3: Paste the prompt into your AI model
    Step 4: Copy the model's complete response
    Step 5: Paste the response into AIQ-X and click Analyze
    Step 6: Review results in the Model Analysis tab
    Step 7: Compare multiple models in the Compare tab

Score Interpretation

    0-20 (Critical): Severe deficiencies, model struggles with basic requirements
    20-40 (Low): Significant limitations, unreliable for most applications
    40-60 (Medium): Adequate baseline capability, suitable for simple tasks
    60-80 (Good): Strong performance, reliable for most applications
    80-100 (Excellent): Outstanding capability, suitable for critical applications

Best Practices

    Run multiple tests over time to track model improvements
    Use consistent model configurations for fair comparisons
    Review detailed responses to understand strengths and weaknesses
    Consider domain-specific requirements when evaluating scores
    Export data regularly for backup purposes

